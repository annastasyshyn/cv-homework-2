{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ab42910-dabd-4f17-b552-d09fa0a616b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/NVlabs/nvdiffrast /tmp/pip-req-build-wd91nwqj\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy >> /dev/null\n",
    "! pip install pandas >> /dev/null\n",
    "! pip install opencv-python >> /dev/null\n",
    "! pip install scipy >> /dev/null\n",
    "! pip install torch >> /dev/null\n",
    "! pip install matplotlib >> /dev/null\n",
    "! pip install git+https://github.com/NVlabs/nvdiffrast >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb91bcb-3ae4-4176-8b5b-3d9d3ea18717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff353fa-1760-4501-acd2-f2b5f4e5ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"data\" # replace with your sequence\n",
    "ORIGINAL_VIDEONAME = \"output/orig.mp4\"\n",
    "UNDISTORTED_VIDEONAME = \"output/undist.mp4\"\n",
    "RS_REMOVED_VIDEONAME = \"output/nors.mp4\"\n",
    "STABILIZED_VIDEONAME = \"output/stable_nors.mp4\"\n",
    "COMPARISON_VIDEONAME = \"output/compar.mp4\"\n",
    "\n",
    "# camera params\n",
    "FPS = 20\n",
    "\n",
    "# camera intrinsics\n",
    "# K = [739.1654756101043, 739.1438452683457, 625.826167006398, 517.3370973594253]\n",
    "K = np.array([[739.1654756101043, 0.0, 625.826167006398],\n",
    "              [0.0, 739.1438452683457, 517.3370973594253],\n",
    "              [0.0, 0.0, 1.0]])\n",
    "\n",
    "# output camera intrinsics\n",
    "K_new = K # pominyatu potim\n",
    "\n",
    "\n",
    "\n",
    "# distortion params\n",
    "D = np.array([0.019327620961435945, 0.006784242994724914, -0.008658628531456217, 0.0051893686731546585])\n",
    "\n",
    "\n",
    "\n",
    "T_cam_imu = np.array([[-0.0027687291789002095, -0.9999872674970001, 0.004218884048773266, -0.05688384754602901],\n",
    "                       [-0.9999356528558058, 0.002814949729190873, 0.010989367855138411, 0.007618902284014501],\n",
    "                       [-0.011001103879489809, -0.004188185992194848, -0.9999307150055582, -0.042436390295094266],\n",
    "                       [0.0, 0.0, 0.0, 1.0]])\n",
    "\n",
    "R_cam_imu = T_cam_imu[:3, :3]\n",
    "\n",
    "\n",
    "dt_rs = 29.47 * 10 ** -6  # in seconds\n",
    "\n",
    "# frame dimensions\n",
    "W, H = 1280, 1024\n",
    "\n",
    "newCameraMatrix, roi = cv2.getOptimalNewCameraMatrix(\n",
    "    K_new, D, (W, H),\n",
    "    alpha=0.0,   # 0 = crop black regions, 1 = keep all pixels\n",
    "    newImgSize=(W, H)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e614ca20-f87a-40dd-a8af-1ded4446154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames in the video: 761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing frames to video: 100%|██████████| 761/761 [00:04<00:00, 183.17it/s]\n"
     ]
    }
   ],
   "source": [
    "def frames_to_video(frames, output_video, fps=20, isColor=False):\n",
    "    \"\"\"\n",
    "    Create a video from a list of frames.\n",
    "\n",
    "    :param frames: list of frames\n",
    "    :param output_video: output video file name (e.g., 'output.mp4')\n",
    "    :param fps: frames per second (default=20)\n",
    "    \"\"\"\n",
    "    if len(frames) == 0:\n",
    "        raise ValueError(\"No frames provided\")\n",
    "\n",
    "    # Use the first frame to get dimensions\n",
    "    height, width, *channels = frames[0].shape\n",
    "\n",
    "    # Define video writer (using mp4v codec)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(output_video, fourcc, fps, (width, height), isColor=isColor)\n",
    "\n",
    "    for frame in tqdm(frames, desc=\"Writing frames to video: \"):\n",
    "        video.write(frame)\n",
    "        \n",
    "\n",
    "frames_paths = sorted(glob.glob(os.path.join(INPUT_DIR, \"cam1/data/*.png\")))\n",
    "print(f\"Number of frames in the video: {len(frames_paths)}\")\n",
    "\n",
    "frames = [cv2.imread(frame_path, cv2.IMREAD_GRAYSCALE) for frame_path in frames_paths]\n",
    "frames_to_video(frames, ORIGINAL_VIDEONAME, FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f48d1732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data = []\n",
    "imgs_folder = INPUT_DIR + \"/cam1\" + \"/data\"\n",
    "for f in os.listdir(imgs_folder):\n",
    "    if os.path.isfile(os.path.join(imgs_folder, f)):\n",
    "        base, ext = os.path.splitext(f)\n",
    "        fid = int(base)\n",
    "        data.append((fid, f))\n",
    "\n",
    "imgs_data = pd.DataFrame(data, columns=[\"timestamp\", \"path\"]).sort_values(\"timestamp\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaa6809-4d6f-4ac8-978f-69c2478b8d4c",
   "metadata": {},
   "source": [
    "### Homework 2\n",
    "\n",
    "Given input video from camera with rolling shutter, implement and apply the following algorithms:\n",
    "\n",
    "    - radial distortion correction (use cv2.fisheye module)\n",
    "    - rolling shutter correction\n",
    "    - video stabilization\n",
    "\n",
    "Expected output of the homework:\n",
    "\n",
    "    - Jupyter notebook with working code that we can run in real-time\n",
    "    - plots of camera orientations in time for unstabilized and stabilized motion [plot individual x/y/z components in axis-angle representation]\n",
    "    - plots of input/output meshgrids for the video frame, where angular velocity has the biggest norm\n",
    "    - 4 videos stacked together with their frames side-by-side:\n",
    "        - original\n",
    "        - undistorted \n",
    "        - undistorted + rolling shutter corrected\n",
    "        - undistorted + rolling shutter corrected + stabilized\n",
    "\n",
    "Note:\n",
    "Dataset used in homework provides two sources of camera orientations: IMU (Gyro) measurements of angular velocity and Motion Capture direct measurements of orientation. You should use IMU (Gyro) measurements and implement angular velocity integration. You can use Motion Capture direct measurements of orientation to verify that your integration is implemented correctly.\n",
    "\n",
    "Rolling shutter correction algorithm is based on this paper: [Digital Video Stabilization and Rolling Shutter Correction using Gyroscopes](https://graphics.stanford.edu/papers/stabilization/).\n",
    "\n",
    "Dataset: [Rolling-Shutter Visual-Inertial Odometry Dataset](https://cvg.cit.tum.de/data/datasets/rolling-shutter-dataset)\n",
    "\n",
    "Calibrated camera params can be found [here](https://cdn3.vision.in.tum.de/rolling/calibration/camchain-calibration-equidistant4_camimu_dataset-calib-imu1.yaml)\n",
    "\n",
    "![Camera Set-up](https://cvg.cit.tum.de/_media/data/datasets/rolling-shutter-dataset/sensor_axes_rgb.jpg?w=800&tok=fa3d4a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f723756",
   "metadata": {},
   "source": [
    "## Preprocessing IMU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2edb933-ded6-4167-9f1b-f0c38158d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_data = pd.read_csv(f\"{INPUT_DIR}/imu0/data.csv\", header=None, dtype=np.float64, skiprows=1)\n",
    "imu_data.columns = [\"timestamp\", \"w_x\", \"w_y\", \"w_z\", \"a_x\", \"a_y\", \"a_z\"]\n",
    "gyro_data = imu_data[[\"timestamp\", \"w_x\", \"w_y\", \"w_z\"]].to_numpy()\n",
    "accel_data = imu_data[[\"timestamp\", \"a_x\", \"a_y\", \"a_z\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a9270f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gyro_timestamps_sec = gyro_data[:, 0] * 1e-9\n",
    "gyro_start = gyro_timestamps_sec[0]\n",
    "gyro_end = gyro_timestamps_sec[-1]\n",
    "gyro_start_time = gyro_start\n",
    "gyro_timestamps_sec -= gyro_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d875c3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(33.763955200000005)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def integrate_gyro(gyro):\n",
    "    dt = np.diff(gyro[:, 0]) * 1e-9\n",
    "    omega = gyro[:, 1:4]\n",
    "    rotations = []\n",
    "\n",
    "    R_curr = R.from_quat([1,0,0,0])\n",
    "    max_rot = 0\n",
    "    max_i = 0\n",
    "\n",
    "    for i, (w, dt_) in enumerate(zip(omega, dt)):\n",
    "        \n",
    "        if np.linalg.norm(w) > max_rot:\n",
    "            max_rot = np.linalg.norm(w)\n",
    "            max_i = i\n",
    "\n",
    "        dR = R.from_rotvec(w * dt_)\n",
    "        R_curr = dR * R_curr\n",
    "        rotations.append(R_curr.as_matrix())\n",
    "\n",
    "    return np.array(rotations), max_i * dt[0]\n",
    "\n",
    "\n",
    "rotations, i = integrate_gyro(gyro_data)\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f41774",
   "metadata": {},
   "source": [
    "## Undistort frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c0a5003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 761/761 [00:16<00:00, 44.83it/s]\n"
     ]
    }
   ],
   "source": [
    "undistorted_frames = [cv2.fisheye.undistortImage(image, K, D, None, K) for image in tqdm(frames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad7a04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing frames to video: 100%|██████████| 761/761 [00:04<00:00, 183.82it/s]\n"
     ]
    }
   ],
   "source": [
    "frames_to_video(undistorted_frames, UNDISTORTED_VIDEONAME, FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def92fd",
   "metadata": {},
   "source": [
    "## Rolling shutter correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41771e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = dt_rs * H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "169c938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def gaussian_low_pass(rotations, sigma=1):\n",
    "    rot_objects = R.from_matrix(rotations)\n",
    "    quats = rot_objects.as_quat()  \n",
    "    smoothed_quats = np.zeros_like(quats)\n",
    "    for i in range(4):\n",
    "        smoothed_quats[:, i] = gaussian_filter1d(quats[:, i], sigma=sigma, mode='nearest')\n",
    "    norms = np.linalg.norm(smoothed_quats, axis=1, keepdims=True)\n",
    "    smoothed_quats = smoothed_quats / norms\n",
    "    \n",
    "    smoothed_rotations = R.from_quat(smoothed_quats).as_matrix()\n",
    "    \n",
    "    return smoothed_rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58518ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device available. Using cuda:0 for warping.\n"
     ]
    }
   ],
   "source": [
    "from meshwarp import MeshWarper\n",
    "meshwarper = MeshWarper()\n",
    "\n",
    "vert_splits = 10\n",
    "rotations_prime = gaussian_low_pass(rotations, sigma=15)\n",
    "rotations_cam_all = np.array([R_cam_imu @ R @ R_cam_imu.T for R in rotations])\n",
    "rotations_prime_cam_all = np.array([R_cam_imu @ R @ R_cam_imu.T for R in rotations_prime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63443b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compensate_rs(frame, rotations_cam_all, rotations_prime_cam_all, K, fps, ts, gyro_timestamps_sec, vert_splits=10, i=0, debug=False):\n",
    "    h, w = frame.shape[:2]\n",
    "    grid_dst, faces = meshwarper.build_meshgrid(w, h, vert_splits, vert_splits)\n",
    "    grid_src = grid_dst.copy()\n",
    "    grid_cols = vert_splits\n",
    "    verts_per_row = grid_cols + 1 \n",
    "    \n",
    "    t_i = i / fps\n",
    "    idx_i = np.searchsorted(gyro_timestamps_sec, t_i)\n",
    "    idx_i = np.clip(idx_i, 0, len(rotations_prime_cam_all) - 1)\n",
    "\n",
    "    if debug:\n",
    "        print(f\">>> Frame {i=} Initial time: {t_i=}, Gyroscope time: {gyro_timestamps_sec[idx_i]}\")\n",
    "\n",
    "    R_prime_ti = rotations_prime_cam_all[idx_i]\n",
    "    \n",
    "    for row_idx in range(vert_splits+1):\n",
    "        y = row_idx * h / vert_splits\n",
    "        t_row = t_i + ts * y / h\n",
    "        \n",
    "        idx = np.searchsorted(gyro_timestamps_sec, t_row)\n",
    "\n",
    "        idx = np.clip(idx, 0, len(rotations_cam_all) - 1)\n",
    "\n",
    "        if debug:\n",
    "            print(f\"----- Row {y=} Row time: {t_row=}, Gyroscope time: {gyro_timestamps_sec[idx]}, idx: {idx=}\")\n",
    "\n",
    "        R_t_row = rotations_cam_all[idx]\n",
    "        \n",
    "        W = K @ R_prime_ti @ R_t_row.T @ np.linalg.inv(K)\n",
    "        start_idx = row_idx * verts_per_row\n",
    "        end_idx = start_idx + verts_per_row\n",
    "        \n",
    "        points_h = np.concatenate([grid_dst[start_idx:end_idx], \n",
    "                                   np.ones((verts_per_row, 1)) ], axis=1)\n",
    "        warped_h = (W @ points_h.T).T\n",
    "        grid_src[start_idx:end_idx] = warped_h[:, :2] / warped_h[:, 2:3]\n",
    "\n",
    "    if debug:\n",
    "        fig, axes = plt.subplots(ncols=2)\n",
    "        axes[0].imshow(meshwarper.draw_meshgrid(grid_src, faces, w, h))\n",
    "        axes[1].imshow(meshwarper.draw_meshgrid(grid_dst, faces, w, h))\n",
    "        plt.show()\n",
    "\n",
    "    corrected = meshwarper.warp_grid(frame, grid_src, grid_dst, faces, (w, h))\n",
    "    return corrected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae335b53",
   "metadata": {},
   "source": [
    "### Output Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac4ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing frames to video: : 761it [00:12, 60.76it/s]\n"
     ]
    }
   ],
   "source": [
    "def crop_image(image, crop):\n",
    "    h, w = image.shape[:2]\n",
    "    return image[crop:h-crop,crop:w-crop]\n",
    "\n",
    "def create_comparison_video(original_frames, undistorted_frames, compensated_frames, stabilized_frames, output_video, fps=20, isColor=False, crop=50):\n",
    "    \"\"\"\n",
    "    Create a video from a list of frames.\n",
    "\n",
    "    :param frames: list of frames\n",
    "    :param output_video: output video file name (e.g., 'output.mp4')\n",
    "    :param fps: frames per second (default=20)\n",
    "    \"\"\"\n",
    "    frames = zip(original_frames, undistorted_frames, compensated_frames, stabilized_frames)\n",
    "    if len(original_frames) == 0:\n",
    "        raise ValueError(\"No frames provided\")\n",
    "    \n",
    "    # Use the first frame to get dimensions\n",
    "    height, width, *channels = undistorted_frames[0].shape\n",
    "    height -= 2 * crop\n",
    "    width -= 2 * crop\n",
    "\n",
    "    # Define video writer (using mp4v codec)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(output_video, fourcc, fps, (3*width, height), isColor=isColor)\n",
    "\n",
    "    for (original, undistorted, compensated, stabilized) in tqdm(frames, desc=\"Writing frames to video: \"):\n",
    "        frame = np.ones((height, 3*width), dtype=np.uint8)\n",
    "\n",
    "        frame[:, :width] = crop_image(undistorted, crop)\n",
    "        frame[:, width:2*width] = crop_image(compensated, crop)\n",
    "        frame[:, 2*width:] = crop_image(stabilized, crop)\n",
    "\n",
    "        video.write(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523d312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device available. Using cuda:0 for warping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "761it [00:10, 74.00it/s]\n",
      "Writing frames to video: : 761it [00:12, 62.33it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "compensated_frames = []\n",
    "stabilized_frames = []\n",
    "\n",
    "\n",
    "for i, frame in tqdm(enumerate(undistorted_frames)):\n",
    "    compensated_frame = compensate_rs(\n",
    "        undistorted_frames[i], \n",
    "        rotations_cam_all,\n",
    "        rotations_cam_all,\n",
    "        newCameraMatrix, \n",
    "        FPS, \n",
    "        ts,\n",
    "        gyro_timestamps_sec,\n",
    "        vert_splits,\n",
    "        i=i\n",
    "    )\n",
    "    compensated_frames.append(compensated_frame)\n",
    "\n",
    "    stabilized_frame = compensate_rs(\n",
    "        undistorted_frames[i], \n",
    "        rotations_cam_all,\n",
    "        rotations_prime_cam_all,\n",
    "        newCameraMatrix, \n",
    "        FPS, \n",
    "        ts,\n",
    "        gyro_timestamps_sec,\n",
    "        vert_splits,\n",
    "        i=i\n",
    "    )\n",
    "    stabilized_frames.append(stabilized_frame)\n",
    "\n",
    "create_comparison_video(\n",
    "    original_frames=frames,\n",
    "    undistorted_frames=undistorted_frames,\n",
    "    compensated_frames=compensated_frames,\n",
    "    stabilized_frames=stabilized_frames,\n",
    "    output_video=COMPARISON_VIDEONAME\n",
    ") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
